{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pyfm import pylibfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train = pd.read_csv('./data/train.csv')\n",
    "d_test = pd.read_csv('./data/test.csv')\n",
    "d_prof = pd.read_csv('./data/profiles.csv')\n",
    "d_artists = pd.read_csv('./data/artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "def loadTrainData(filename,path=\"./data/\"):\n",
    "    data = []\n",
    "    y = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            (user,movieid,rating)=line.strip().split(',')\n",
    "            data.append({ \"user_id\": str(user), \"movie_id\": str(movieid)})\n",
    "            y.append(float(rating))\n",
    "            users.add(user)\n",
    "            items.add(movieid)\n",
    "\n",
    "    return (data, np.array(y), users, items)\n",
    "\n",
    "def loadTestData(filename,path=\"./data/\"):\n",
    "    data = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            (Id,user,movieid)=line.split(',')\n",
    "            data.append({ \"user_id\": str(user), \"movie_id\": str(movieid)})\n",
    "            users.add(user)\n",
    "            items.add(movieid)\n",
    "\n",
    "    return (data, users, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_profiles=set(d_prof['user'].values)\n",
    "artists_artists=set(d_artists['artist'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dictionary for users id\n",
    "dict_users=dict(zip(users_profiles, range(len(users_profiles))))\n",
    "#dictionary for artists id\n",
    "dict_artists=dict(zip(artists_artists, range(len(artists_artists))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 260084.50039\n",
      "-- Epoch 2\n",
      "Training MSE: 258072.29178\n",
      "-- Epoch 3\n",
      "Training MSE: 257997.58225\n",
      "-- Epoch 4\n",
      "Training MSE: 257923.80142\n",
      "-- Epoch 5\n",
      "Training MSE: 257847.67711\n",
      "-- Epoch 6\n",
      "Training MSE: 257757.28072\n",
      "-- Epoch 7\n",
      "Training MSE: 257616.81034\n",
      "-- Epoch 8\n",
      "Training MSE: 257309.57222\n",
      "-- Epoch 9\n",
      "Training MSE: 256463.07133\n",
      "-- Epoch 10\n",
      "Training MSE: 253927.87874\n",
      "-- Epoch 11\n",
      "Training MSE: 247057.31508\n",
      "-- Epoch 12\n",
      "Training MSE: 234878.74455\n",
      "-- Epoch 13\n",
      "Training MSE: 227538.62074\n",
      "-- Epoch 14\n",
      "Training MSE: 223219.90873\n",
      "-- Epoch 15\n",
      "Training MSE: 220303.45278\n",
      "-- Epoch 16\n",
      "Training MSE: 216967.67312\n",
      "-- Epoch 17\n",
      "Training MSE: 211644.31472\n",
      "-- Epoch 18\n",
      "Training MSE: 204328.29947\n",
      "-- Epoch 19\n",
      "Training MSE: 195952.84688\n",
      "-- Epoch 20\n",
      "Training MSE: 187209.57576\n",
      "-- Epoch 21\n",
      "Training MSE: 178295.56496\n",
      "-- Epoch 22\n",
      "Training MSE: 169393.02050\n",
      "-- Epoch 23\n",
      "Training MSE: 160693.41298\n",
      "-- Epoch 24\n",
      "Training MSE: 152486.97802\n",
      "-- Epoch 25\n",
      "Training MSE: 145077.72852\n",
      "-- Epoch 26\n",
      "Training MSE: 138582.21335\n",
      "-- Epoch 27\n",
      "Training MSE: 132851.47456\n",
      "-- Epoch 28\n",
      "Training MSE: 127645.36060\n",
      "-- Epoch 29\n",
      "Training MSE: 122747.44901\n",
      "-- Epoch 30\n",
      "Training MSE: 118087.41880\n",
      "-- Epoch 31\n",
      "Training MSE: 113593.50380\n",
      "-- Epoch 32\n",
      "Training MSE: 109266.19239\n",
      "-- Epoch 33\n",
      "Training MSE: 105075.36254\n",
      "-- Epoch 34\n",
      "Training MSE: 101024.84076\n",
      "-- Epoch 35\n",
      "Training MSE: 97121.89666\n",
      "-- Epoch 36\n",
      "Training MSE: 93383.44014\n",
      "-- Epoch 37\n",
      "Training MSE: 89813.17977\n",
      "-- Epoch 38\n",
      "Training MSE: 86430.44973\n",
      "-- Epoch 39\n",
      "Training MSE: 83231.24557\n",
      "-- Epoch 40\n",
      "Training MSE: 80208.91370\n",
      "-- Epoch 41\n",
      "Training MSE: 77361.76065\n",
      "-- Epoch 42\n",
      "Training MSE: 74659.14937\n",
      "-- Epoch 43\n",
      "Training MSE: 72113.62099\n",
      "-- Epoch 44\n",
      "Training MSE: 69692.92252\n",
      "-- Epoch 45\n",
      "Training MSE: 67405.60091\n",
      "-- Epoch 46\n",
      "Training MSE: 65249.17288\n",
      "-- Epoch 47\n",
      "Training MSE: 63195.72259\n",
      "-- Epoch 48\n",
      "Training MSE: 61269.12024\n",
      "-- Epoch 49\n",
      "Training MSE: 59437.18807\n",
      "-- Epoch 50\n",
      "Training MSE: 57702.44013\n",
      "-- Epoch 51\n",
      "Training MSE: 56074.53048\n",
      "-- Epoch 52\n",
      "Training MSE: 54496.54226\n",
      "-- Epoch 53\n",
      "Training MSE: 53020.51112\n",
      "-- Epoch 54\n",
      "Training MSE: 51598.29477\n",
      "-- Epoch 55\n",
      "Training MSE: 50252.32630\n",
      "-- Epoch 56\n",
      "Training MSE: 48952.80600\n",
      "-- Epoch 57\n",
      "Training MSE: 47723.29856\n",
      "-- Epoch 58\n",
      "Training MSE: 46526.22016\n",
      "-- Epoch 59\n",
      "Training MSE: 45392.69924\n",
      "-- Epoch 60\n",
      "Training MSE: 44294.11237\n",
      "-- Epoch 61\n",
      "Training MSE: 43251.82537\n",
      "-- Epoch 62\n",
      "Training MSE: 42237.37531\n",
      "-- Epoch 63\n",
      "Training MSE: 41266.59674\n",
      "-- Epoch 64\n",
      "Training MSE: 40323.39784\n",
      "-- Epoch 65\n",
      "Training MSE: 39416.15333\n",
      "-- Epoch 66\n",
      "Training MSE: 38550.75083\n",
      "-- Epoch 67\n",
      "Training MSE: 37685.55978\n",
      "-- Epoch 68\n",
      "Training MSE: 36867.45279\n",
      "-- Epoch 69\n",
      "Training MSE: 36082.12774\n",
      "-- Epoch 70\n",
      "Training MSE: 35292.04827\n",
      "-- Epoch 71\n",
      "Training MSE: 34530.12524\n",
      "-- Epoch 72\n",
      "Training MSE: 33816.07402\n",
      "-- Epoch 73\n",
      "Training MSE: 33091.80468\n",
      "-- Epoch 74\n",
      "Training MSE: 32405.66595\n",
      "-- Epoch 75\n",
      "Training MSE: 31712.01447\n",
      "-- Epoch 76\n",
      "Training MSE: 31062.11214\n",
      "-- Epoch 77\n",
      "Training MSE: 30409.21733\n",
      "-- Epoch 78\n",
      "Training MSE: 29777.56540\n",
      "-- Epoch 79\n",
      "Training MSE: 29184.97470\n",
      "-- Epoch 80\n",
      "Training MSE: 28568.14017\n",
      "-- Epoch 81\n",
      "Training MSE: 27985.62677\n",
      "-- Epoch 82\n",
      "Training MSE: 27425.05026\n",
      "-- Epoch 83\n",
      "Training MSE: 26858.57909\n",
      "-- Epoch 84\n",
      "Training MSE: 26322.64101\n",
      "-- Epoch 85\n",
      "Training MSE: 25792.67840\n",
      "-- Epoch 86\n",
      "Training MSE: 25280.21451\n",
      "-- Epoch 87\n",
      "Training MSE: 24794.07201\n",
      "-- Epoch 88\n",
      "Training MSE: 24295.90378\n",
      "-- Epoch 89\n",
      "Training MSE: 23822.61639\n",
      "-- Epoch 90\n",
      "Training MSE: 23366.97547\n",
      "-- Epoch 91\n",
      "Training MSE: 22905.08673\n",
      "-- Epoch 92\n",
      "Training MSE: 22475.88109\n",
      "-- Epoch 93\n",
      "Training MSE: 22053.83924\n",
      "-- Epoch 94\n",
      "Training MSE: 21633.44581\n",
      "-- Epoch 95\n",
      "Training MSE: 21229.82500\n",
      "-- Epoch 96\n",
      "Training MSE: 20836.00036\n",
      "-- Epoch 97\n",
      "Training MSE: 20454.16511\n",
      "-- Epoch 98\n",
      "Training MSE: 20089.16598\n",
      "-- Epoch 99\n",
      "Training MSE: 19719.90129\n",
      "-- Epoch 100\n",
      "Training MSE: 19375.47876\n",
      "-- Epoch 101\n",
      "Training MSE: 19022.00864\n",
      "-- Epoch 102\n",
      "Training MSE: 18686.28624\n",
      "-- Epoch 103\n",
      "Training MSE: 18362.60204\n",
      "-- Epoch 104\n",
      "Training MSE: 18040.48832\n",
      "-- Epoch 105\n",
      "Training MSE: 17730.27351\n",
      "-- Epoch 106\n",
      "Training MSE: 17434.60351\n",
      "-- Epoch 107\n",
      "Training MSE: 17130.97532\n",
      "-- Epoch 108\n",
      "Training MSE: 16846.32082\n",
      "-- Epoch 109\n",
      "Training MSE: 16566.36160\n",
      "-- Epoch 110\n",
      "Training MSE: 16289.75962\n",
      "-- Epoch 111\n",
      "Training MSE: 16026.39637\n",
      "-- Epoch 112\n",
      "Training MSE: 15770.53116\n",
      "-- Epoch 113\n",
      "Training MSE: 15505.72114\n",
      "-- Epoch 114\n",
      "Training MSE: 15262.64657\n",
      "-- Epoch 115\n",
      "Training MSE: 15018.28760\n",
      "-- Epoch 116\n",
      "Training MSE: 14781.70411\n",
      "-- Epoch 117\n",
      "Training MSE: 14555.67559\n",
      "-- Epoch 118\n",
      "Training MSE: 14327.17235\n",
      "-- Epoch 119\n",
      "Training MSE: 14111.97742\n",
      "-- Epoch 120\n",
      "Training MSE: 13890.14140\n",
      "-- Epoch 121\n",
      "Training MSE: 13682.06133\n",
      "-- Epoch 122\n",
      "Training MSE: 13482.78271\n",
      "-- Epoch 123\n",
      "Training MSE: 13275.60011\n",
      "-- Epoch 124\n",
      "Training MSE: 13087.27956\n",
      "-- Epoch 125\n",
      "Training MSE: 12897.37365\n",
      "-- Epoch 126\n",
      "Training MSE: 12708.52629\n",
      "-- Epoch 127\n",
      "Training MSE: 12534.91754\n",
      "-- Epoch 128\n",
      "Training MSE: 12349.98496\n",
      "-- Epoch 129\n",
      "Training MSE: 12183.91255\n",
      "-- Epoch 130\n",
      "Training MSE: 12006.54493\n",
      "-- Epoch 131\n",
      "Training MSE: 11839.61247\n",
      "-- Epoch 132\n",
      "Training MSE: 11683.39680\n",
      "-- Epoch 133\n",
      "Training MSE: 11534.29077\n",
      "-- Epoch 134\n",
      "Training MSE: 11373.14042\n",
      "-- Epoch 135\n",
      "Training MSE: 11226.77495\n",
      "-- Epoch 136\n",
      "Training MSE: 11077.51084\n",
      "-- Epoch 137\n",
      "Training MSE: 10939.24437\n",
      "-- Epoch 138\n",
      "Training MSE: 10801.37127\n",
      "-- Epoch 139\n"
     ]
    }
   ],
   "source": [
    "(train_data, y_train, train_users, train_items) = loadTrainData('train.csv')\n",
    "(test_data, test_users, test_items) = loadTestData(\"test.csv\")\n",
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(train_data)\n",
    "X_test = v.transform(test_data)\n",
    "\n",
    "# Build and train a Factorization Machine\n",
    "fm = pylibfm.FM(num_factors=100, num_iter=500, verbose=True, task=\"regression\", initial_learning_rate=1e-6, learning_rate_schedule=\"optimal\")\n",
    "\n",
    "fm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_users = len(d_prof.user)\n",
    "num_artists = len(d_artists)\n",
    "Ndim = 10\n",
    "lbd = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=d_train['plays'].values\n",
    "data_norm = np.double(data) / max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rating matrix\n",
    "row=[dict_users[i] for i in d_train['user'].values]\n",
    "col=[dict_artists[i] for i in d_train['artist'].values]\n",
    "RMat=csr_matrix((data_norm, (row, col)), shape=(num_users, num_artists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matrix factorization\n",
    "#P_user = np.ones([num_users, Ndim])\n",
    "#Q_art = np.ones([num_artists, Ndim])\n",
    "P_user = np.random.rand(num_users, Ndim)\n",
    "Q_art = np.random.rand(num_artists, Ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14510.423634 seconds process time\n"
     ]
    }
   ],
   "source": [
    "numIter = 0\n",
    "maxIter = 100\n",
    "yita = 0.001\n",
    "ErrVec = np.zeros(numIter)\n",
    "t0 = time.clock()\n",
    "while numIter < 100:\n",
    "    # loop over training set\n",
    "    for tr in d_train.values:\n",
    "        u = dict_users[tr[0]]\n",
    "        a = dict_artists[tr[1]]\n",
    "        rate = tr[2]\n",
    "        p_u = P_user[u, :]\n",
    "        q_a = Q_art[a, :]\n",
    "        Err = RMat[u, a] - np.dot(p_u, q_a)\n",
    "        p_u = p_u + yita*(Err*q_a-lbd*p_u)\n",
    "        q_a = q_a + yita*(Err*p_u-lbd*q_a)\n",
    "        #print p_new\n",
    "        #rint q_new\n",
    "        P_user[u, :] = p_u\n",
    "        Q_art[a, :] = q_a\n",
    "#         if numIter > 10000:\n",
    "#             break\n",
    "    # calculate error\n",
    "#     for tr in d_train.values:\n",
    "#         u = dict_users[tr[0]]\n",
    "#         a = dict_artists[tr[1]]\n",
    "#         rate = tr[2]\n",
    "#         p_u = P_user[u, :]\n",
    "#         q_a = Q_art[a, :]\n",
    "#         ErrVec[numIter] += RMat[u, a] - np.dot(p_u, q_a)\n",
    "#     if ErrVec[numIter] < 0.1:\n",
    "#         print 'err smaller than 0.001, numLoop:', numIter\n",
    "#         break\n",
    "    numIter += 1\n",
    "print time.clock() - t0, \"seconds process time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.87816642e-05,   1.20004923e-04,   1.22392421e-04, ...,\n",
       "          1.56154891e-04,   1.15391705e-04,   7.67940657e-05],\n",
       "       [  3.38697341e-04,   1.23089923e-04,   2.11607648e-04, ...,\n",
       "          1.39878924e-04,   1.19596138e-04,   4.36085306e-05],\n",
       "       [  5.90304217e-05,   4.19185033e-05,   1.50955826e-04, ...,\n",
       "          8.62375350e-05,   9.87862306e-05,   1.25716585e-04],\n",
       "       ..., \n",
       "       [  2.06705238e-04,   1.27445877e-04,   1.83317150e-04, ...,\n",
       "          1.74474019e-04,   9.99966211e-05,   1.03595759e-04],\n",
       "       [  1.57581672e-04,   1.57165700e-04,   1.53954898e-04, ...,\n",
       "          8.31431302e-05,   1.48812804e-04,  -1.22429660e-05],\n",
       "       [  7.68036655e-05,   1.11633773e-04,   7.25608346e-05, ...,\n",
       "          4.24426778e-05,   1.02153193e-04,   1.13658411e-04]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86252341,  0.54441578,  0.37208828, ...,  0.67664195,\n",
       "         0.18824546,  0.64020052],\n",
       "       [ 0.93991752,  0.64114049,  0.98100957, ...,  0.49941717,\n",
       "         0.85338248,  0.85966756],\n",
       "       [ 0.17271683,  0.98830942,  0.56421805, ...,  0.03465758,\n",
       "         0.83038321,  0.05105259],\n",
       "       ..., \n",
       "       [ 0.91093163,  0.33463205,  0.16468657, ...,  0.70577038,\n",
       "         0.7750251 ,  0.63143624],\n",
       "       [ 0.93545673,  0.66579405,  0.09680115, ...,  0.39475343,\n",
       "         0.31151672,  0.08343328],\n",
       "       [ 0.79499278,  0.97529649,  0.06261903, ...,  0.20586603,\n",
       "         0.55278331,  0.46895966]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('userMat', P_user)\n",
    "np.save('artMat', Q_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     0,      0,      0, ..., 233285, 233285, 233285], dtype=int32),\n",
       " array([ 147,  422,  524, ..., 1516, 1670, 1739], dtype=int32),\n",
       " array([  2.00402236e-04,   1.19287045e-04,   1.43144454e-04, ...,\n",
       "          9.54296362e-05,   5.01005590e-05,   3.74561322e-04]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.find(RMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4154804, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = pd.read_csv('mat_factorization.csv')\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file = './data/train.csv'\n",
    "test_file  = './data/test.csv'\n",
    "soln_file  = './data/user_median.csv'\n",
    "\n",
    "# Load the training data.\n",
    "train_data = {}\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = row[2]\n",
    "    \n",
    "        if not user in train_data:\n",
    "            train_data[user] = {}\n",
    "        \n",
    "        train_data[user][artist] = int(plays)\n",
    "\n",
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "for user, user_data in train_data.iteritems():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419157"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxValue = max(data)\n",
    "maxValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read mat\n",
    "P_user = np.load('userMat.npy')\n",
    "Q_art = np.load('artMat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soln_file  = 'mat_factorization.csv'\n",
    "\n",
    "# write solution\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "        Iter = 0\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "            u = dict_users[user]\n",
    "            a = dict_artists[artist]\n",
    "            p_u = P_user[u, :]\n",
    "            q_a = Q_art[a, :]\n",
    "            res = np.round(np.dot(p_u, q_a)*maxValue)\n",
    "            if res < 0:\n",
    "                res = np.round(user_medians[user])\n",
    "            soln_csv.writerow([id, res])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
